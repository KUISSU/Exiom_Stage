{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760570e4",
   "metadata": {},
   "source": [
    "# Modélisation des probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "467ab83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esthelle.kuissu\\AppData\\Local\\Temp\\ipykernel_22088\\4172452751.py:7: DtypeWarning: Columns (24,83) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  datap = pd.read_csv(path + \"\\\\bdd_sinistres_MODELPROBA.csv\", sep=\";\", encoding=\"utf-8\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.getcwd()\n",
    "\n",
    "path = \"c:\\\\Users\\\\esthelle.kuissu\\\\OneDrive - Exiom Partners\\\\Documents\\\\Code_rapport_stage\\\\Bases sinistres\"\n",
    "\n",
    "datap = pd.read_csv(path + \"\\\\bdd_sinistres_MODELPROBA.csv\", sep=\";\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c65b0612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " structure_id structure_grp  n_sinistres\n",
      "            1            MO           15\n",
      "            2         MO+IP        81351\n",
      "            3     MO+PIECES          356\n",
      "            4     IP+PIECES           26\n",
      "            5  MO+IP+PIECES       920097\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 0. Noms des colonnes montants\n",
    "# --------------------------------------------------------------------------\n",
    "mo_col    = \"MT_MO_REPARABLE\"\n",
    "ip_col    = \"MT_IP_REPARABLE\"\n",
    "piece_col = \"MT_PIECES_REPARABLE\"\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 1. Variable texte brute : combinaison exacte des postes > 0\n",
    "# --------------------------------------------------------------------------\n",
    "def structure_postes(row):\n",
    "    postes = []\n",
    "    if row[mo_col]    > 0: postes.append(\"MO\")\n",
    "    if row[ip_col]    > 0: postes.append(\"IP\")\n",
    "    if row[piece_col] > 0: postes.append(\"PIECES\")\n",
    "    return \"+\".join(postes) if postes else \"AUCUN\"\n",
    "\n",
    "datap[\"structure_sinistre\"] = datap.apply(structure_postes, axis=1)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 2. Fusion souhaitée → nouvelle variable `structure_grp`\n",
    "#    • IP  regroupe  {IP, MO+IP}\n",
    "#    • PIECES regroupe {PIECES, MO+PIECES}\n",
    "# --------------------------------------------------------------------------\n",
    "map_fusion = {\n",
    "    \"MO\"              : \"MO\",\n",
    "    \"IP\"              : \"MO+IP\",\n",
    "    \"MO+IP\"           : \"MO+IP\",          # fusion ici\n",
    "    \"PIECES\"          : \"MO+PIECES\",\n",
    "    \"MO+PIECES\"       : \"MO+PIECES\",      # fusion ici\n",
    "    \"IP+PIECES\"       : \"IP+PIECES\",\n",
    "    \"MO+IP+PIECES\"    : \"MO+IP+PIECES\",\n",
    "    \"AUCUN\"           : \"AUCUN\"\n",
    "}\n",
    "\n",
    "datap[\"structure_grp\"] = datap[\"structure_sinistre\"].map(map_fusion)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 3. Identifiant numérique  (tu peux changer les numéros si besoin)\n",
    "# --------------------------------------------------------------------------\n",
    "map_id = {\n",
    "    \"MO\"              : 1,\n",
    "    \"MO+IP\"              : 2,\n",
    "    \"MO+PIECES\"          : 3,\n",
    "    \"IP+PIECES\"       : 4,\n",
    "    \"MO+IP+PIECES\"    : 5,\n",
    "    \"AUCUN\"           : 0          # facultatif\n",
    "}\n",
    "\n",
    "datap[\"structure_id\"] = datap[\"structure_grp\"].map(map_id)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 4. Table de fréquence : pour contrôle\n",
    "# --------------------------------------------------------------------------\n",
    "freq = (\n",
    "    datap.groupby([\"structure_id\", \"structure_grp\"])\n",
    "         .size()\n",
    "         .reset_index(name=\"n_sinistres\")\n",
    "         .sort_values(\"structure_id\")\n",
    ")\n",
    "\n",
    "print(freq.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1fb3ee81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb de sinistres 'PIECES seule' : 0\n"
     ]
    }
   ],
   "source": [
    "pieces_seul = datap[\n",
    "    (datap['MT_PIECES_REPARABLE'] > 0) &\n",
    "    (datap['MT_MO_REPARABLE'] == 0) &\n",
    "    (datap['MT_IP_REPARABLE'] == 0)\n",
    "]\n",
    "print(\"Nb de sinistres 'PIECES seule' :\", len(pieces_seul))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7743736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cle_sin', 'date_evt', 'date_evt_decla', 'clos', 'sans_suite', 'quart_resp', 'date_premsous', 'date_dernrempl', 'formule_ratt', 'cond_indet', 'date_nais', 'age', 'date_permis', 'anc_permis', 'sexe', 'profess', 'sitfam', 'orig_attest', 'aac', 'date_sortie_veh', 'age_veh', 'usage2', 'franch', 'rachat_francBG', 'garag', 'marq', 'modele2', 'generation', 'modele_desc', 'caros', 'segment', 'energ', 'num_sra', 'cylin', 'pdyne', 'pkw', 'pfisc', 'vites', 'pvid', 'poidspuiss', 'sport', 'frein', 'cdval', 'trans', 'alim', 'suspe', 'boite', 'val', 'couple', 'airbag', 'crash', 'co2min', 'elt_secu', 'vu', 'pickup', 'luxe', 'prestige', 'soumis_crm', 'crm', 'boncond', 'nab50', 'bureau_ratt', 'fract_paiem_soc', 'formule_gar', 'petit_rouleur', 'systeme', 'exercice', 'GARANTIE_HOST', 'MT_FRANCHISE', 'MT_CHARGE_BRUTE', 'MT_CHARGE_NETTE', 'MT_REGLEMENT_SIN', 'MT_REGLEMENT_COM', 'MT_ABANDON_RECOURS', 'MT_FRAIS_HONO', 'MT_PROVISIONS', 'MT_RECOURS_TOTAL', 'MT_ESTIMATION_RECOURS_RESTANTS', 'MT_AVANCE_RECOURS', 'MT_AVANCE_RECOURS_RECOURUS', 'MT_PAIEMENTS', 'MT_CHARGE_BRUTE_ECO', 'MT_CHARGE_NETTE_ECO', 'ZN_NO_RAPPORT_EXPTIS', 'MT_VAL_REMPL_VEH_TTC', 'MT_TOTAL_REPARABLE', 'NB_REP', 'MT_MO_REPARABLE', 'NBHH_MO_REPARABLE', 'TAUX_HORAIRE_MO', 'MT_IP_REPARABLE', 'NBHH_IP_REPARABLE', 'MT_PIECES_REPARABLE', 'NB_PIECES_REEMPLOI', 'MT_PIECES_REEMPLOI', 'RE_AVEC_PIECE_REEMPLOI', 'RE_AVEC_PIECE_REPAR_MP', 'RE_AVEC_PIECE_REMPL_MP', 'MT_REMISE', 'MT_FORFAIT', 'MT_FORFAIT_ERD', 'LIB_CHOC', 'LIB_INTENS', 'GARAGE_AGREE_O_N', 'DPT_REP', '_RESEAU_', 'NB_PIECE_REMPLACEE', 'NB_PIECE_REPAREE', 'veh_info_manquante', 'date_ord', 'date_sortie_veh_imputee', 'annee_sortie_veh', 'date_nais_f', 'date_permis_f', 'formule_ratt_g', 'sitfam_g', 'usage2_g', 'orig_attest_g', 'caros_g', 'segment_g', 'energ_g', 'frein_g', 'alim_g', 'suspe_g', 'crash_g', 'fract_paiem_soc_g', 'cdval_g', 'modele2_g', 'profess_g', 'marq_g', 'garag_g', 'Region', 'Zone', 'structure_sinistre', 'structure_grp', 'structure_id']\n"
     ]
    }
   ],
   "source": [
    "print(list(datap.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ada576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Création des colonnes indicatrices (uint8 → 0/1)\n",
    "dummies = pd.get_dummies(datap['exercice'], prefix='year').astype(int)\n",
    "\n",
    "# (Optionnel) on retire l’année de base 2019 pour éviter la colinéarité\n",
    "dummies = dummies.drop(columns=['year_2019'])\n",
    "\n",
    "# Fusion avec ton DataFrame\n",
    "datap = pd.concat([datap, dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02ff84fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 variables de montant supprimées.\n",
      "116 variables conservées.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 0) ton DataFrame initial ----------------------------------------------------\n",
    "# df = pd.read_csv(\"ton_fichier.csv\")  # ou déjà présent en mémoire\n",
    "\n",
    "# 1) liste explicite de TOUTES tes variables (copiée depuis ta question) -----\n",
    "all_vars = [\n",
    "    'cle_sin', 'date_evt', 'date_evt_decla', 'clos', 'sans_suite', 'quart_resp',\n",
    "    'date_premsous', 'date_dernrempl', 'formule_ratt', 'cond_indet', 'date_nais',\n",
    "    'age', 'date_permis', 'anc_permis', 'sexe', 'profess', 'sitfam', 'orig_attest',\n",
    "    'aac', 'date_sortie_veh', 'age_veh', 'usage2', 'franch', 'rachat_francBG',\n",
    "    'garag', 'marq', 'modele2', 'generation', 'modele_desc', 'caros', 'segment',\n",
    "    'energ', 'num_sra', 'cylin', 'pdyne', 'pkw', 'pfisc', 'vites', 'pvid',\n",
    "    'poidspuiss', 'sport', 'frein', 'cdval', 'trans', 'alim', 'suspe', 'boite',\n",
    "    'val', 'couple', 'airbag', 'crash', 'co2min', 'elt_secu', 'vu', 'pickup',\n",
    "    'luxe', 'prestige', 'soumis_crm', 'crm', 'boncond', 'nab50', 'bureau_ratt',\n",
    "    'fract_paiem_soc', 'formule_gar', 'petit_rouleur', 'systeme', 'exercice',\n",
    "    'GARANTIE_HOST', 'MT_FRANCHISE', 'MT_CHARGE_BRUTE', 'MT_CHARGE_NETTE',\n",
    "    'MT_REGLEMENT_SIN', 'MT_REGLEMENT_COM', 'MT_ABANDON_RECOURS', 'MT_FRAIS_HONO',\n",
    "    'MT_PROVISIONS', 'MT_RECOURS_TOTAL', 'MT_ESTIMATION_RECOURS_RESTANTS',\n",
    "    'MT_AVANCE_RECOURS', 'MT_AVANCE_RECOURS_RECOURUS', 'MT_PAIEMENTS',\n",
    "    'MT_CHARGE_BRUTE_ECO', 'MT_CHARGE_NETTE_ECO', 'ZN_NO_RAPPORT_EXPTIS',\n",
    "    'MT_VAL_REMPL_VEH_TTC', 'MT_TOTAL_REPARABLE', 'NB_REP', 'MT_MO_REPARABLE',\n",
    "    'NBHH_MO_REPARABLE', 'TAUX_HORAIRE_MO', 'MT_IP_REPARABLE',\n",
    "    'NBHH_IP_REPARABLE', 'MT_PIECES_REPARABLE', 'NB_PIECES_REEMPLOI',\n",
    "    'MT_PIECES_REEMPLOI', 'RE_AVEC_PIECE_REEMPLOI', 'RE_AVEC_PIECE_REPAR_MP',\n",
    "    'RE_AVEC_PIECE_REMPL_MP', 'MT_REMISE', 'MT_FORFAIT', 'MT_FORFAIT_ERD',\n",
    "    'LIB_CHOC', 'LIB_INTENS', 'GARAGE_AGREE_O_N', 'DPT_REP', '_RESEAU_',\n",
    "    'NB_PIECE_REMPLACEE', 'NB_PIECE_REPAREE', 'veh_info_manquante', 'date_ord',\n",
    "    'date_sortie_veh_imputee', 'annee_sortie_veh', 'date_nais_f',\n",
    "    'date_permis_f', 'formule_ratt_g', 'sitfam_g', 'usage2_g', 'orig_attest_g',\n",
    "    'caros_g', 'segment_g', 'energ_g', 'frein_g', 'alim_g', 'suspe_g',\n",
    "    'crash_g', 'fract_paiem_soc_g', 'cdval_g', 'modele2_g', 'profess_g',\n",
    "    'marq_g', 'garag_g', 'Region', 'Zone', 'structure_sinistre', 'structure_id',\n",
    "    'year_2020', 'year_2021', 'year_2022', 'year_2023', 'year_2024'\n",
    "]\n",
    "\n",
    "# 2) distinguer variables montants vs non montants ---------------------------\n",
    "montants     = [v for v in all_vars if v.startswith('MT_')]\n",
    "non_montants = [v for v in all_vars if v not in montants]\n",
    "\n",
    "print(f\"{len(montants)} variables de montant supprimées.\")\n",
    "print(f\"{len(non_montants)} variables conservées.\")\n",
    "\n",
    "# 3) créer la base sans montants ---------------------------------------------\n",
    "datap_sm = datap[non_montants].copy()\n",
    "\n",
    "# 4) enregistrer si besoin ----------------------------------------------------\n",
    "#datap_sm.to_csv(\"baseproba_sans_montants.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9da7fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cle_sin</th>\n",
       "      <th>date_evt</th>\n",
       "      <th>date_evt_decla</th>\n",
       "      <th>clos</th>\n",
       "      <th>sans_suite</th>\n",
       "      <th>quart_resp</th>\n",
       "      <th>date_premsous</th>\n",
       "      <th>date_dernrempl</th>\n",
       "      <th>formule_ratt</th>\n",
       "      <th>cond_indet</th>\n",
       "      <th>...</th>\n",
       "      <th>garag_g</th>\n",
       "      <th>Region</th>\n",
       "      <th>Zone</th>\n",
       "      <th>structure_sinistre</th>\n",
       "      <th>structure_id</th>\n",
       "      <th>year_2020</th>\n",
       "      <th>year_2021</th>\n",
       "      <th>year_2022</th>\n",
       "      <th>year_2023</th>\n",
       "      <th>year_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>191840439C  A   018</td>\n",
       "      <td>02/01/2019</td>\n",
       "      <td>04/01/2019</td>\n",
       "      <td>O</td>\n",
       "      <td>N</td>\n",
       "      <td>plus_50pc</td>\n",
       "      <td>29/06/1987</td>\n",
       "      <td>09/01/2015</td>\n",
       "      <td>PRO</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>Petit garage</td>\n",
       "      <td>Nouvelle-Aquitaine</td>\n",
       "      <td>Ouest</td>\n",
       "      <td>MO+IP+PIECES</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191840048C  A   001</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>02/01/2019</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>plus_50pc</td>\n",
       "      <td>10/11/2018</td>\n",
       "      <td>2023-12-31 00:00:00</td>\n",
       "      <td>PRO</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>Garage moyen</td>\n",
       "      <td>Pays de la Loire</td>\n",
       "      <td>Ouest</td>\n",
       "      <td>MO+IP+PIECES</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191840501C  A   010</td>\n",
       "      <td>03/01/2019</td>\n",
       "      <td>04/01/2019</td>\n",
       "      <td>O</td>\n",
       "      <td>N</td>\n",
       "      <td>plus_50pc</td>\n",
       "      <td>13/07/2016</td>\n",
       "      <td>03/04/2018</td>\n",
       "      <td>PRO</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>Garage moyen</td>\n",
       "      <td>Pays de la Loire</td>\n",
       "      <td>Ouest</td>\n",
       "      <td>MO+IP+PIECES</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>191840759C  A   001</td>\n",
       "      <td>06/01/2019</td>\n",
       "      <td>07/01/2019</td>\n",
       "      <td>O</td>\n",
       "      <td>N</td>\n",
       "      <td>plus_50pc</td>\n",
       "      <td>25/10/2015</td>\n",
       "      <td>2023-12-31 00:00:00</td>\n",
       "      <td>PRO</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>Garage moyen</td>\n",
       "      <td>Pays de la Loire</td>\n",
       "      <td>Ouest</td>\n",
       "      <td>MO+IP+PIECES</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191840075AV A   003</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>02/01/2019</td>\n",
       "      <td>O</td>\n",
       "      <td>N</td>\n",
       "      <td>plus_50pc</td>\n",
       "      <td>10/06/2015</td>\n",
       "      <td>11/03/2016</td>\n",
       "      <td>PRO</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>Garage moyen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>MO+IP+PIECES</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cle_sin    date_evt date_evt_decla clos sans_suite quart_resp  \\\n",
       "0  191840439C  A   018  02/01/2019     04/01/2019    O          N  plus_50pc   \n",
       "1  191840048C  A   001  01/01/2019     02/01/2019    N          N  plus_50pc   \n",
       "2  191840501C  A   010  03/01/2019     04/01/2019    O          N  plus_50pc   \n",
       "3  191840759C  A   001  06/01/2019     07/01/2019    O          N  plus_50pc   \n",
       "4  191840075AV A   003  01/01/2019     02/01/2019    O          N  plus_50pc   \n",
       "\n",
       "  date_premsous       date_dernrempl formule_ratt cond_indet  ...  \\\n",
       "0    29/06/1987           09/01/2015          PRO          N  ...   \n",
       "1    10/11/2018  2023-12-31 00:00:00          PRO          N  ...   \n",
       "2    13/07/2016           03/04/2018          PRO          N  ...   \n",
       "3    25/10/2015  2023-12-31 00:00:00          PRO          N  ...   \n",
       "4    10/06/2015           11/03/2016          PRO          N  ...   \n",
       "\n",
       "        garag_g              Region   Zone  structure_sinistre structure_id  \\\n",
       "0  Petit garage  Nouvelle-Aquitaine  Ouest        MO+IP+PIECES            5   \n",
       "1  Garage moyen    Pays de la Loire  Ouest        MO+IP+PIECES            5   \n",
       "2  Garage moyen    Pays de la Loire  Ouest        MO+IP+PIECES            5   \n",
       "3  Garage moyen    Pays de la Loire  Ouest        MO+IP+PIECES            5   \n",
       "4  Garage moyen                 NaN      I        MO+IP+PIECES            5   \n",
       "\n",
       "  year_2020 year_2021 year_2022 year_2023 year_2024  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datap_sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e3f19a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cle_sin', 'date_evt', 'date_evt_decla', 'clos', 'sans_suite', 'quart_resp', 'date_premsous', 'date_dernrempl', 'formule_ratt', 'cond_indet', 'date_nais', 'age', 'date_permis', 'anc_permis', 'sexe', 'profess', 'sitfam', 'orig_attest', 'aac', 'date_sortie_veh', 'age_veh', 'usage2', 'franch', 'rachat_francBG', 'garag', 'marq', 'modele2', 'generation', 'modele_desc', 'caros', 'segment', 'energ', 'num_sra', 'cylin', 'pdyne', 'pkw', 'pfisc', 'vites', 'pvid', 'poidspuiss', 'sport', 'frein', 'cdval', 'trans', 'alim', 'suspe', 'boite', 'val', 'couple', 'airbag', 'crash', 'co2min', 'elt_secu', 'vu', 'pickup', 'luxe', 'prestige', 'soumis_crm', 'crm', 'boncond', 'nab50', 'bureau_ratt', 'fract_paiem_soc', 'formule_gar', 'petit_rouleur', 'systeme', 'exercice', 'GARANTIE_HOST', 'ZN_NO_RAPPORT_EXPTIS', 'NB_REP', 'NBHH_MO_REPARABLE', 'TAUX_HORAIRE_MO', 'NBHH_IP_REPARABLE', 'NB_PIECES_REEMPLOI', 'RE_AVEC_PIECE_REEMPLOI', 'RE_AVEC_PIECE_REPAR_MP', 'RE_AVEC_PIECE_REMPL_MP', 'LIB_CHOC', 'LIB_INTENS', 'GARAGE_AGREE_O_N', 'DPT_REP', '_RESEAU_', 'NB_PIECE_REMPLACEE', 'NB_PIECE_REPAREE', 'veh_info_manquante', 'date_ord', 'date_sortie_veh_imputee', 'annee_sortie_veh', 'date_nais_f', 'date_permis_f', 'formule_ratt_g', 'sitfam_g', 'usage2_g', 'orig_attest_g', 'caros_g', 'segment_g', 'energ_g', 'frein_g', 'alim_g', 'suspe_g', 'crash_g', 'fract_paiem_soc_g', 'cdval_g', 'modele2_g', 'profess_g', 'marq_g', 'garag_g', 'Region', 'Zone', 'structure_sinistre', 'structure_id', 'year_2020', 'year_2021', 'year_2022', 'year_2023', 'year_2024']\n"
     ]
    }
   ],
   "source": [
    "print(list(datap_sm.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b699b09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 variables initiales → 62 après exclusion.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 1. Liste des variables à exclure\n",
    "# ---------------------------------------------\n",
    "exclure = [\n",
    "    'date_evt_decla', 'clos', 'sans_suite', 'quart_resp', 'date_premsous',\n",
    "    'date_dernrempl', 'formule_ratt', 'cond_indet', 'date_nais', 'Zone',\n",
    "    'date_permis', 'anc_permis', 'sexe', 'profess', 'sitfam', 'orig_attest',\n",
    "    'date_sortie_veh', 'usage2', 'franch', 'rachat_francBG',\n",
    "    'garag', 'marq', 'modele2', 'generation', 'modele_desc', 'caros',\n",
    "    'segment', 'energ', 'num_sra', 'cylin', 'pdyne', 'pfisc', 'vites',\n",
    "    'pvid', 'bureau_ratt', 'fract_paiem_soc', 'formule_gar', 'petit_rouleur',\n",
    "    'systeme', 'exercice', 'GARANTIE_HOST', 'ZN_NO_RAPPORT_EXPTIS', 'NB_REP',\n",
    "    'NBHH_MO_REPARABLE', 'TAUX_HORAIRE_MO', 'NBHH_IP_REPARABLE',\n",
    "    'NB_PIECES_REEMPLOI', 'RE_AVEC_PIECE_REEMPLOI', 'RE_AVEC_PIECE_REPAR_MP',\n",
    "    'RE_AVEC_PIECE_REMPL_MP', 'veh_info_manquante', 'date_ord',\n",
    "    'date_sortie_veh_imputee', 'DPT_REP'\n",
    "]\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2. Variable d’origine : par ex. non_montants\n",
    "#    (remplace par le nom réel de ta liste)\n",
    "# ---------------------------------------------\n",
    "# non_montants = [...]  # ta liste existante\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3. Création de la nouvelle liste filtrée\n",
    "# ---------------------------------------------\n",
    "vars_filtrees = [col for col in non_montants if col not in exclure]\n",
    "\n",
    "print(f\"{len(non_montants)} variables initiales → {len(vars_filtrees)} après exclusion.\")\n",
    "\n",
    "datap_s = datap_sm[vars_filtrees].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "79a2886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cle_sin', 'date_evt', 'age', 'aac', 'age_veh', 'pkw', 'poidspuiss', 'sport', 'frein', 'cdval', 'trans', 'alim', 'suspe', 'boite', 'val', 'couple', 'airbag', 'crash', 'co2min', 'elt_secu', 'vu', 'pickup', 'luxe', 'prestige', 'soumis_crm', 'crm', 'boncond', 'nab50', 'LIB_CHOC', 'LIB_INTENS', 'GARAGE_AGREE_O_N', '_RESEAU_', 'NB_PIECE_REMPLACEE', 'NB_PIECE_REPAREE', 'annee_sortie_veh', 'date_nais_f', 'date_permis_f', 'formule_ratt_g', 'sitfam_g', 'usage2_g', 'orig_attest_g', 'caros_g', 'segment_g', 'energ_g', 'frein_g', 'alim_g', 'suspe_g', 'crash_g', 'fract_paiem_soc_g', 'cdval_g', 'modele2_g', 'profess_g', 'marq_g', 'garag_g', 'Region', 'structure_sinistre', 'structure_id', 'year_2020', 'year_2021', 'year_2022', 'year_2023', 'year_2024']\n"
     ]
    }
   ],
   "source": [
    "print(list(datap_s.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ebd1cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) enregistrer si besoin ----------------------------------------------------\n",
    "datap_s.to_csv(path + \"basefinproba_sans_montants.csv\", index=False, encoding=\"utf-8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68ac93d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cle_sin</th>\n",
       "      <th>date_evt</th>\n",
       "      <th>age</th>\n",
       "      <th>aac</th>\n",
       "      <th>age_veh</th>\n",
       "      <th>pkw</th>\n",
       "      <th>poidspuiss</th>\n",
       "      <th>sport</th>\n",
       "      <th>frein</th>\n",
       "      <th>cdval</th>\n",
       "      <th>...</th>\n",
       "      <th>marq_g</th>\n",
       "      <th>garag_g</th>\n",
       "      <th>Region</th>\n",
       "      <th>structure_sinistre</th>\n",
       "      <th>structure_id</th>\n",
       "      <th>year_2020</th>\n",
       "      <th>year_2021</th>\n",
       "      <th>year_2022</th>\n",
       "      <th>year_2023</th>\n",
       "      <th>year_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>191840439C  A   018</td>\n",
       "      <td>02/01/2019</td>\n",
       "      <td>84.0</td>\n",
       "      <td>N</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>nn_spt</td>\n",
       "      <td>ABS</td>\n",
       "      <td>V06</td>\n",
       "      <td>...</td>\n",
       "      <td>Généralistes</td>\n",
       "      <td>Petit garage</td>\n",
       "      <td>Nouvelle-Aquitaine</td>\n",
       "      <td>MO+IP+PIECES</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191840048C  A   001</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>18.0</td>\n",
       "      <td>O</td>\n",
       "      <td>6.0</td>\n",
       "      <td>51.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>nn_spt</td>\n",
       "      <td>ABS</td>\n",
       "      <td>V06</td>\n",
       "      <td>...</td>\n",
       "      <td>Autres</td>\n",
       "      <td>Garage moyen</td>\n",
       "      <td>Pays de la Loire</td>\n",
       "      <td>MO+IP+PIECES</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191840501C  A   010</td>\n",
       "      <td>03/01/2019</td>\n",
       "      <td>67.0</td>\n",
       "      <td>N</td>\n",
       "      <td>6.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>spt</td>\n",
       "      <td>ABS</td>\n",
       "      <td>V24</td>\n",
       "      <td>...</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Garage moyen</td>\n",
       "      <td>Pays de la Loire</td>\n",
       "      <td>MO+IP+PIECES</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>191840759C  A   001</td>\n",
       "      <td>06/01/2019</td>\n",
       "      <td>40.0</td>\n",
       "      <td>N</td>\n",
       "      <td>12.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>nn_spt</td>\n",
       "      <td>ABS</td>\n",
       "      <td>V09</td>\n",
       "      <td>...</td>\n",
       "      <td>Généralistes</td>\n",
       "      <td>Garage moyen</td>\n",
       "      <td>Pays de la Loire</td>\n",
       "      <td>MO+IP+PIECES</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191840075AV A   003</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>47.0</td>\n",
       "      <td>N</td>\n",
       "      <td>3.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>nn_spt</td>\n",
       "      <td>ABS</td>\n",
       "      <td>V11</td>\n",
       "      <td>...</td>\n",
       "      <td>Généralistes</td>\n",
       "      <td>Garage moyen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MO+IP+PIECES</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cle_sin    date_evt   age aac  age_veh    pkw  poidspuiss  \\\n",
       "0  191840439C  A   018  02/01/2019  84.0   N      3.0   66.0        12.0   \n",
       "1  191840048C  A   001  01/01/2019  18.0   O      6.0   51.5        15.0   \n",
       "2  191840501C  A   010  03/01/2019  67.0   N      6.0  180.0         7.0   \n",
       "3  191840759C  A   001  06/01/2019  40.0   N     12.0   78.0        13.0   \n",
       "4  191840075AV A   003  01/01/2019  47.0   N      3.0   84.0        12.0   \n",
       "\n",
       "    sport frein cdval  ...        marq_g       garag_g              Region  \\\n",
       "0  nn_spt   ABS   V06  ...  Généralistes  Petit garage  Nouvelle-Aquitaine   \n",
       "1  nn_spt   ABS   V06  ...        Autres  Garage moyen    Pays de la Loire   \n",
       "2     spt   ABS   V24  ...       Premium  Garage moyen    Pays de la Loire   \n",
       "3  nn_spt   ABS   V09  ...  Généralistes  Garage moyen    Pays de la Loire   \n",
       "4  nn_spt   ABS   V11  ...  Généralistes  Garage moyen                 NaN   \n",
       "\n",
       "  structure_sinistre  structure_id  year_2020  year_2021 year_2022  year_2023  \\\n",
       "0       MO+IP+PIECES             5          0          0         0          0   \n",
       "1       MO+IP+PIECES             5          0          0         0          0   \n",
       "2       MO+IP+PIECES             5          0          0         0          0   \n",
       "3       MO+IP+PIECES             5          0          0         0          0   \n",
       "4       MO+IP+PIECES             5          0          0         0          0   \n",
       "\n",
       "  year_2024  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datap_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cb1f8108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "print(len(list(datap_s.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0e11f8",
   "metadata": {},
   "source": [
    "## Petite sélection de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dae983f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Remplace 'sparse' par 'sparse_output'\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3100c272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 variables numériques retenues\n",
      "39 variables qualitatives retenues\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "to_exclude = set()\n",
    "\n",
    "# a) identifiants, cible\n",
    "to_exclude.update(['cle_sin', 'structure_id', 'structure_sinistre'])\n",
    "\n",
    "\n",
    "# c) éventuellement d’autres colonnes (dates si tu ne les transformes pas)\n",
    "to_exclude.update(['date_evt', 'date_premsous'])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1) Détection auto : quali vs quanti\n",
    "# ------------------------------------------------------------------\n",
    "# numériques : int, float, bool\n",
    "quant_vars = [\n",
    "    c for c in datap_s.columns\n",
    "    if (datap_s[c].dtype.kind in 'iufcb')    # integer, unsigned, float, complex, bool\n",
    "    and c not in to_exclude\n",
    "]\n",
    "\n",
    "# qualitatives : object ou category\n",
    "qual_vars = [\n",
    "    c for c in datap_s.columns\n",
    "    if (datap_s[c].dtype == 'object' or str(datap_s[c].dtype) == 'category')\n",
    "    and c not in to_exclude\n",
    "]\n",
    "\n",
    "print(f\"{len(quant_vars)} variables numériques retenues\")\n",
    "print(f\"{len(qual_vars)} variables qualitatives retenues\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96a212c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# 1. Sous-ensemble : uniquement les variables quantitatives\n",
    "# -----------------------------------------------------------------\n",
    "X = datap_s[quant_vars].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "34efc3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables quantitatives avec valeurs manquantes :\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Comptage des NaN pour chaque variable quantitative\n",
    "nan_counts = datap_s[quant_vars].isna().sum()\n",
    "\n",
    "# Affiche uniquement celles qui ont au moins un NaN\n",
    "print(\"Variables quantitatives avec valeurs manquantes :\")\n",
    "print(nan_counts[nan_counts > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e2cfcb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            variable          VIF\n",
      "13  annee_sortie_veh  1228.068416\n",
      "9            boncond  1104.917826\n",
      "2                pkw    87.964159\n",
      "3         poidspuiss    49.000396\n",
      "8                crm    39.228716\n",
      "4                val    36.179551\n",
      "0                age    18.552097\n",
      "7             co2min    17.605847\n",
      "5             couple    12.064447\n",
      "6             airbag    10.377932\n",
      "1            age_veh     4.139207\n",
      "10             nab50     2.754166\n",
      "12  NB_PIECE_REPAREE     2.327961\n",
      "18         year_2024     2.289180\n",
      "17         year_2023     2.135326\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame({\n",
    "    \"variable\": X.columns,\n",
    "    \"VIF\"     : [variance_inflation_factor(X.values, i)\n",
    "                 for i in range(X.shape[1])]\n",
    "})\n",
    "print(vif.sort_values(\"VIF\", ascending=False).head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "df874994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "\n",
    "def calcul_vif(X):\n",
    "    \"\"\"Calcule les VIFs pour chaque variable de X.\"\"\"\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variable\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif\n",
    "\n",
    "def supprimer_vif(X, seuil=10):\n",
    "    \"\"\"Supprime récursivement les variables avec un VIF supérieur au seuil.\"\"\"\n",
    "    X_clean = X.copy()\n",
    "    iteration = 1\n",
    "    while True:\n",
    "        vif = calcul_vif(X_clean)\n",
    "        max_vif = vif[\"VIF\"].max()\n",
    "        if max_vif > seuil:\n",
    "            var_a_suppr = vif.sort_values(\"VIF\", ascending=False).iloc[0][\"variable\"]\n",
    "            print(f\"[Itération {iteration}] Suppression de '{var_a_suppr}' avec VIF = {max_vif:.2f}\")\n",
    "            X_clean = X_clean.drop(columns=[var_a_suppr])\n",
    "            iteration += 1\n",
    "        else:\n",
    "            break\n",
    "    print(f\"\\n✅ Variables finales conservées ({X_clean.shape[1]}):\\n{list(X_clean.columns)}\")\n",
    "    return X_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "161a8b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Itération 1] Suppression de 'annee_sortie_veh' avec VIF = 1228.07\n",
      "[Itération 2] Suppression de 'boncond' avec VIF = 190.56\n",
      "[Itération 3] Suppression de 'pkw' avec VIF = 59.43\n",
      "[Itération 4] Suppression de 'crm' avec VIF = 18.01\n",
      "[Itération 5] Suppression de 'val' avec VIF = 13.75\n",
      "[Itération 6] Suppression de 'age' avec VIF = 11.99\n",
      "[Itération 7] Suppression de 'co2min' avec VIF = 10.45\n",
      "\n",
      "✅ Variables finales conservées (12):\n",
      "['age_veh', 'poidspuiss', 'couple', 'airbag', 'nab50', 'NB_PIECE_REMPLACEE', 'NB_PIECE_REPAREE', 'year_2020', 'year_2021', 'year_2022', 'year_2023', 'year_2024']\n"
     ]
    }
   ],
   "source": [
    "X_vif_clean = supprimer_vif(X, seuil=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f40de3",
   "metadata": {},
   "source": [
    "VAR QUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "434fdd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              level_0   level_1  CramerV\n",
      "140             cdval   cdval_g      1.0\n",
      "298             crash   crash_g      1.0\n",
      "203              alim    alim_g      1.0\n",
      "510  GARAGE_AGREE_O_N  _RESEAU_      1.0\n",
      "100             frein   frein_g      1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def cramer_v(x, y):\n",
    "    \"\"\"Cramér’s V pour deux variables catégorielles pandas (sans correction).\"\"\"\n",
    "    confusion = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion, correction=False)[0]\n",
    "    n    = confusion.sum().sum()\n",
    "    k,r  = confusion.shape               # colonnes, lignes\n",
    "    return np.sqrt(chi2 / (n * (min(k, r) - 1)))\n",
    "\n",
    "def matrice_cramer(df, cat_cols):\n",
    "    \"\"\"Renvoie une matrice DataFrame de Cramér’s V pour toutes les paires.\"\"\"\n",
    "    V = pd.DataFrame(index=cat_cols, columns=cat_cols, dtype=float)\n",
    "    for i, col1 in enumerate(cat_cols):\n",
    "        for col2 in cat_cols[i:]:\n",
    "            V.loc[col1, col2] = V.loc[col2, col1] = cramer_v(df[col1], df[col2])\n",
    "    return V\n",
    "\n",
    "# --- utilisation ------------------------------------------------------------\n",
    "cat_cols = qual_vars                            # tes variables qualitatives\n",
    "V = matrice_cramer(datap_s, cat_cols)\n",
    "\n",
    "# lister les couples très corrélés (|V| > 0.7)\n",
    "thr = 0.7\n",
    "corr_pairs = (\n",
    "    V.where(np.triu(np.ones(V.shape), k=1).astype(bool))\n",
    "      .stack()\n",
    "      .reset_index()\n",
    "      .rename(columns={0: 'CramerV'})\n",
    "      .query('CramerV > @thr')\n",
    "      .sort_values('CramerV', ascending=False)\n",
    ")\n",
    "print(corr_pairs.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "477e7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_remove = [\n",
    "    'cdval',\n",
    "    'crash',\n",
    "    'alim',\n",
    "    '_RESEAU_',  # ou GARAGE_AGREE_O_N\n",
    "    'frein'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "46bce3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "datap_s = datap_s.drop(columns=vars_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000a049c",
   "metadata": {},
   "source": [
    "# ARRET ICI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a7a3e406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 colonnes au départ → 55 conservées\n",
      "['age', 'aac', 'age_veh', 'pkw', 'poidspuiss', 'sport', 'trans', 'suspe', 'boite', 'val', 'couple', 'airbag', 'co2min', 'elt_secu', 'vu'] ...\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 1. Liste des variables à exclure\n",
    "# ------------------------------------------------------------------\n",
    "exclude_cols = {'date_evt', 'cle_sin'}   # ajoute-en d'autres si besoin\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Création de vars_final\n",
    "# ------------------------------------------------------------------\n",
    "vars_final = [col for col in datap_s.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"{len(datap_s.columns)} colonnes au départ → {len(vars_final)} conservées\")\n",
    "print(vars_final[:15], \"...\")   # aperçu des 15 premières\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "11752ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cle_sin', 'date_evt', 'age', 'aac', 'age_veh', 'pkw', 'poidspuiss', 'sport', 'trans', 'suspe', 'boite', 'val', 'couple', 'airbag', 'co2min', 'elt_secu', 'vu', 'pickup', 'luxe', 'prestige', 'soumis_crm', 'crm', 'boncond', 'nab50', 'LIB_CHOC', 'LIB_INTENS', 'GARAGE_AGREE_O_N', 'NB_PIECE_REMPLACEE', 'NB_PIECE_REPAREE', 'annee_sortie_veh', 'date_nais_f', 'date_permis_f', 'formule_ratt_g', 'sitfam_g', 'usage2_g', 'orig_attest_g', 'caros_g', 'segment_g', 'energ_g', 'frein_g', 'alim_g', 'suspe_g', 'crash_g', 'fract_paiem_soc_g', 'cdval_g', 'modele2_g', 'profess_g', 'marq_g', 'garag_g', 'Region', 'structure_sinistre', 'structure_id', 'year_2020', 'year_2021', 'year_2022', 'year_2023', 'year_2024']\n"
     ]
    }
   ],
   "source": [
    "print(list(datap_s.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4eb9f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# a) Colonnes finales\n",
    "#    - vars_final_num  : toutes les quantitatives retenues\n",
    "#    - vars_final_cat  : toutes les qualitatives retenues\n",
    "# ------------------------------------------------------------\n",
    "vars_final_num = [v for v in vars_final if datap_s[v].dtype.kind in \"iufcb\"]\n",
    "vars_final_cat = [v for v in vars_final if v not in vars_final_num]\n",
    "\n",
    "X = datap_s[vars_final_num + vars_final_cat]        # matrice explicative\n",
    "y = datap_s[\"structure_id\"]                        # variable cible (1 à 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3cf39f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6e40ed5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 335. GiB for an array with shape (801476, 56065) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     11\u001b[39m model = Pipeline([\n\u001b[32m     12\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mprep\u001b[39m\u001b[33m\"\u001b[39m, preproc),\n\u001b[32m     13\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mclf\u001b[39m\u001b[33m\"\u001b[39m,  LogisticRegression(\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m                 n_jobs=-\u001b[32m1\u001b[39m))\n\u001b[32m     18\u001b[39m ])\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------------\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# c) Entraînement\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLog-loss in-sample :\u001b[39m\u001b[33m\"\u001b[39m, log_loss(y_test, model.predict_proba(X_test)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:653\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    647\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    648\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m     )\n\u001b[32m    652\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:587\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    580\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    581\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    582\u001b[39m     step_idx=step_idx,\n\u001b[32m    583\u001b[39m     step_params=routed_params[name],\n\u001b[32m    584\u001b[39m     all_params=raw_params,\n\u001b[32m    585\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m587\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\joblib\\memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:1539\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1538\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1539\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1540\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1541\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1542\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1543\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:996\u001b[39m, in \u001b[36mColumnTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    994\u001b[39m     routed_params = \u001b[38;5;28mself\u001b[39m._get_empty_routing()\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[32m   1005\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fitted_transformers([])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:897\u001b[39m, in \u001b[36mColumnTransformer._call_func_on_transformers\u001b[39m\u001b[34m(self, X, y, func, column_as_labels, routed_params)\u001b[39m\n\u001b[32m    885\u001b[39m             extra_args = {}\n\u001b[32m    886\u001b[39m         jobs.append(\n\u001b[32m    887\u001b[39m             delayed(func)(\n\u001b[32m    888\u001b[39m                 transformer=clone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[32m   (...)\u001b[39m\u001b[32m    894\u001b[39m             )\n\u001b[32m    895\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected 2D array, got 1D array instead\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:1539\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1538\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1539\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1540\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1541\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1542\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1543\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\base.py:895\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    892\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, **fit_params).transform(X)\n\u001b[32m    893\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    894\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1083\u001b[39m, in \u001b[36mOneHotEncoder.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1077\u001b[39m out = sparse.csr_matrix(\n\u001b[32m   1078\u001b[39m     (data, indices, indptr),\n\u001b[32m   1079\u001b[39m     shape=(n_samples, feature_indices[-\u001b[32m1\u001b[39m]),\n\u001b[32m   1080\u001b[39m     dtype=\u001b[38;5;28mself\u001b[39m.dtype,\n\u001b[32m   1081\u001b[39m )\n\u001b[32m   1082\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sparse_output:\n\u001b[32m-> \u001b[39m\u001b[32m1083\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1085\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:996\u001b[39m, in \u001b[36m_cs_matrix.toarray\u001b[39m\u001b[34m(self, order, out)\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    995\u001b[39m     order = \u001b[38;5;28mself\u001b[39m._swap(\u001b[33m'\u001b[39m\u001b[33mcf\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out.flags.c_contiguous \u001b[38;5;129;01mor\u001b[39;00m out.flags.f_contiguous):\n\u001b[32m    998\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mOutput array must be C or F contiguous\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\esthelle.kuissu\\OneDrive - Exiom Partners\\Documents\\Exiom_stage\\Exiom_Stage\\.venv\\Lib\\site-packages\\scipy\\sparse\\_base.py:1527\u001b[39m, in \u001b[36m_spbase._process_toarray_args\u001b[39m\u001b[34m(self, order, out)\u001b[39m\n\u001b[32m   1525\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m   1526\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 335. GiB for an array with shape (801476, 56065) and data type float64"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# b) Pipeline : One-hot + régression multinomiale\n",
    "# ------------------------------------------------------------\n",
    "preproc = ColumnTransformer(\n",
    "    [(\"cat\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\",\n",
    "                            sparse_output=False),\n",
    "      vars_final_cat)],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"prep\", preproc),\n",
    "    (\"clf\",  LogisticRegression(\n",
    "                multi_class=\"multinomial\",\n",
    "                solver=\"lbfgs\",\n",
    "                max_iter=400,\n",
    "                n_jobs=-1))\n",
    "])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# c) Entraînement\n",
    "# ------------------------------------------------------------\n",
    "model.fit(X_train,y_train)\n",
    "print(\"Log-loss in-sample :\", log_loss(y_test, model.predict_proba(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682df68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23339a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "pipe_lasso = Pipeline([\n",
    "    ('prep', preprocessor),                        # One-hot + numériques\n",
    "    ('clf',  LogisticRegression(\n",
    "                penalty='l1', solver='saga',\n",
    "                multi_class='multinomial', max_iter=400))\n",
    "])\n",
    "\n",
    "param_C = {'clf__C': np.logspace(-3, 2, 12)}      # grille de pénalités\n",
    "cv      = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_lasso = GridSearchCV(pipe_lasso,\n",
    "                          param_grid=param_C,\n",
    "                          cv=cv,\n",
    "                          scoring='neg_log_loss',\n",
    "                          n_jobs=-1)\n",
    "grid_lasso.fit(datap_s[qual_vars + quant_vars + year_dummies], datap_s['structure_id'])\n",
    "\n",
    "print(\"C optimal :\", grid_lasso.best_params_['clf__C'])\n",
    "print(\"Log-loss :\", -grid_lasso.best_score_)\n",
    "\n",
    "# variables conservées (≠ 0)\n",
    "best_clf   = grid_lasso.best_estimator_.named_steps['clf']\n",
    "coef_mask  = np.any(best_clf.coef_ != 0, axis=0)\n",
    "selected   = np.array(grid_lasso.best_estimator_\n",
    "                      .named_steps['prep']\n",
    "                      .get_feature_names_out())[coef_mask]\n",
    "print(\"Variables retenues par Lasso :\", selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c78490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def stepwise_selection(X, y, criterion='bic'):\n",
    "    \"\"\"Simplifié : ajoute/supprime jusqu’à ce que BIC (ou AIC) cesse d’améliorer.\"\"\"\n",
    "    remaining = list(X.columns)\n",
    "    selected  = []\n",
    "    current_score, best_new_score = np.inf, np.inf\n",
    "    while remaining:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            model = sm.MNLogit(y, sm.add_constant(X[selected + [candidate]])).fit(disp=0)\n",
    "            score = model.bic if criterion=='bic' else model.aic\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates[0]\n",
    "        if best_new_score < current_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "        else:\n",
    "            break\n",
    "    return selected\n",
    "\n",
    "X_step = pd.get_dummies(datap_s[qual_vars + quant_vars + year_dummies], drop_first=True)\n",
    "y      = datap_s['structure_id']\n",
    "vars_BIC = stepwise_selection(X_step, y, criterion='bic')\n",
    "print(\"Variables retenues (BIC) :\", vars_BIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabec7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "X_rf = pd.get_dummies(datap_s[qual_vars + quant_vars + year_dummies], drop_first=True)\n",
    "rf.fit(X_rf, y)\n",
    "\n",
    "perm = permutation_importance(rf, X_rf, y,\n",
    "                              scoring='neg_log_loss', n_repeats=5, n_jobs=-1)\n",
    "imp  = pd.Series(perm.importances_mean, index=X_rf.columns).sort_values(ascending=False)\n",
    "print(\"Top 20 importances permutation :\")\n",
    "print(imp.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
